<mods xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.loc.gov/mods/v3" version="3.3" xsi:schemaLocation="http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-3-3.xsd"><id>2302401</id><setSpec>bi_dissertation</setSpec><setSpec>doc-type:doctoralThesis</setSpec><setSpec>ddc:510</setSpec><setSpec>bi_dissertationFtxt</setSpec><setSpec>open_access</setSpec>

<genre>thesis</genre>

<titleInfo><title>Multilayer neural networks : learnability, network generation, and network simplification</title></titleInfo>





<name type="personal">
  <namePart type="given">Thomas M.</namePart>
  <namePart type="family">Ellerbrock</namePart>
  <role><roleTerm type="text">author</roleTerm> </role></name>





<name type="personal">
  
  <namePart type="given">Philippe</namePart>
  
  
  <namePart type="family">Blanchard</namePart>
  
  <role> <roleTerm type="text">supervisor</roleTerm> </role>
</name>



<name type="corporate">
  <namePart/>
  <identifier type="local">10028</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>








<abstract lang="eng">Chapter 1 of this book shall give a little impression of the theoretical diversity of the non-trivial theory of multilayer neural networks (multilayer perceptrons). This diversity comprises ideas from Approximation Theory, Measure and Probability Theory, Statistics, the Theory of NP-Completeness, Geometry, Topology and Graph Theory.
In Chapter 2 a new perspective in learning and generalization of multilayer perceptrons is introduced.
Proposing a definition of 'representativity' for training sets, we proved that multilayer perceptrons are able to realize 'topologically adequate solutions' to classification problems whenever the training set is representative of the problem to learn. Using concepts from topology and combinatorial geometry, the definition 'adequate solution' gives the notion of 'generalization' a precise mathematical meaning. This way, connectivity properties of the classes to be learned are taken into account.
In contrast to the known results concerning the approximation capabilities of neural networks, here classes are not approximated by functions but by sets. This is done directly with respect to the training set.
In Chapter 3 an algorithm is introduced which generates modular multilayer neural networks for classification problems. Computer simulations are presented and discussed with respect to generalization, adequate solutions, learning and network structure.
In Chapter 4 a new iterative pruning method for a variety of neural network architectures is given.
Successively from all neurons in the net, all connections and thresholds are removed which can be removed without changing the input output behavior of the neurons. Organizing the local input space into an acyclic directed graph, only a small portion of the input space (called test inputs) needs to be used to decide whether a set of neuron parameters (synaptic connections and thresholds) can be removed or not. Furthermore, the optimum order for the presentation of test inputs has been computed.
These theoretical and numerical results are combined with theorems on the optimum order and optimum number of neuron parameters to be removed in each iteration step.</abstract>

<relatedItem type="constituent">
  <location>
    <url displayLabel="1_ellerbrock_title.ps">https://pub.uni-bielefeld.de/download/2302401/2302405/1_ellerbrock_title.ps</url>
  </location>
  <physicalDescription><internetMediaType>application/ps</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<relatedItem type="constituent">
  <location>
    <url displayLabel="container.tgz">https://pub.uni-bielefeld.de/download/2302401/2302404/container.tgz</url>
  </location>
  <physicalDescription><internetMediaType>application/x-gzip</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<relatedItem type="constituent">
  <location>
    <url displayLabel="2_ellerbrock_diss.ps">https://pub.uni-bielefeld.de/download/2302401/2302406/2_ellerbrock_diss.ps</url>
  </location>
  <physicalDescription><internetMediaType>application/ps</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<originInfo><publisher>Bielefeld University</publisher><dateIssued encoding="w3cdtf">1999</dateIssued>
</originInfo>
<language><languageTerm authority="iso639-2b" type="code">eng</languageTerm>
</language>

<subject><topic>Mehrschichten-Perzeptron ,  , Multilayer perceptrons , Network structuring , Generalization , Network architecture</topic>
</subject>


<relatedItem type="host"><identifier type="urn">urn:nbn:de:hbz:361-1301</identifier>
<part>
</part>
</relatedItem>


<dateOther encoding="w3cdtf" type="defenseDate">1999-03-17</dateOther>
<extension>
<bibliographicCitation>
<default>Ellerbrock TM (1999) &lt;br /&gt;Bielefeld (Germany): Bielefeld University.</default>
<frontiers>Ellerbrock, T. M. (1999). Multilayer neural networks : learnability, network generation, and network simplification. Bielefeld (Germany): Bielefeld University.</frontiers>
<mla>Ellerbrock, Thomas M. &lt;em&gt;Multilayer neural networks : learnability, network generation, and network simplification&lt;/em&gt;. Bielefeld (Germany): Bielefeld University, 1999.</mla>
<apa_indent>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Ellerbrock, T. M. (1999).  &lt;em&gt;Multilayer neural networks : learnability, network generation, and network simplification&lt;/em&gt;. Bielefeld (Germany): Bielefeld University.&lt;/div&gt;</apa_indent>
<wels>Ellerbrock, T. M. (1999): Multilayer neural networks : learnability, network generation, and network simplification. Bielefeld (Germany): Bielefeld University.</wels>
<apa>Ellerbrock, T. M. (1999).  &lt;em&gt;Multilayer neural networks : learnability, network generation, and network simplification&lt;/em&gt;. Bielefeld (Germany): Bielefeld University.</apa>
<ieee> T.M. Ellerbrock, &lt;em&gt;Multilayer neural networks : learnability, network generation, and network simplification&lt;/em&gt;,  Bielefeld (Germany): Bielefeld University, 1999.</ieee>
<harvard1>Ellerbrock, T.M., 1999. &lt;em&gt;Multilayer neural networks : learnability, network generation, and network simplification&lt;/em&gt;, Bielefeld (Germany): Bielefeld University.</harvard1>
<bio1>Ellerbrock TM (1999) &lt;br /&gt;&lt;em&gt;Multilayer neural networks : learnability, network generation, and network simplification&lt;/em&gt;.&lt;br /&gt;Bielefeld (Germany): Bielefeld University.</bio1>
<angewandte-chemie>T. M.  Ellerbrock, &lt;em&gt;Multilayer neural networks : learnability, network generation, and network simplification&lt;/em&gt;, Bielefeld University, Bielefeld (Germany), &lt;strong&gt;1999&lt;/strong&gt;.</angewandte-chemie>
<dgps>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Ellerbrock, T.M. (1999). &lt;em&gt;Multilayer neural networks : learnability, network generation, and network simplification&lt;/em&gt;. Bielefeld (Germany): Bielefeld University.&lt;/div&gt;</dgps>
<lncs> Ellerbrock, T.M.: Multilayer neural networks : learnability, network generation, and network simplification. Bielefeld University, Bielefeld (Germany) (1999).</lncs>
<chicago>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Ellerbrock, Thomas M. 1999. &lt;em&gt;Multilayer neural networks : learnability, network generation, and network simplification&lt;/em&gt;. Bielefeld (Germany): Bielefeld University.&lt;/div&gt;</chicago>
<ama>Ellerbrock TM. &lt;em&gt;Multilayer neural networks : learnability, network generation, and network simplification&lt;/em&gt;. Bielefeld (Germany): Bielefeld University; 1999.</ama>
</bibliographicCitation>
</extension>
<recordInfo><recordIdentifier>2302401</recordIdentifier><recordCreationDate encoding="w3cdtf">2003-03-24T12:31:13Z</recordCreationDate><recordChangeDate encoding="w3cdtf">2020-03-11T08:47:32Z</recordChangeDate>
</recordInfo>
</mods>