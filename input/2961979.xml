<mods xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.loc.gov/mods/v3" version="3.3" xsi:schemaLocation="http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-3-3.xsd"><id>2961979</id><setSpec>bi_dissertation</setSpec><setSpec>doc-type:doctoralThesis</setSpec><setSpec>ddc:000</setSpec><setSpec>bi_dissertationFtxt</setSpec><setSpec>open_access</setSpec>

<genre>thesis</genre>

<titleInfo><title>Learning in non-stationary Environments</title></titleInfo>





<name type="personal">
  <namePart type="given">Christoph</namePart>
  <namePart type="family">Raab</namePart>
  <role><roleTerm type="text">author</roleTerm> </role></name>





<name type="personal">
  
  <namePart type="given">Barbara</namePart>
  
  
  <namePart type="family">Hammer</namePart>
  
  <role> <roleTerm type="text">supervisor</roleTerm> </role>
</name>

<name type="personal">
  
  <namePart type="given">Frank-Michael</namePart>
  
  
  <namePart type="family">Schleif</namePart>
  
  <role> <roleTerm type="text">supervisor</roleTerm> </role>
</name>



<name type="corporate">
  <namePart/>
  <identifier type="local">10037</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>

<name type="corporate">
  <namePart/>
  <identifier type="local">8014655</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>








<abstract lang="eng">The topic of Machine Learning deals with learning a data-based decision function. This function assigns correct output information based on input data. The learning process is performed in a laboratory domain and finally applied in a test or application domain. Typically, the distribution of data between the learning and application domain is assumed to be the same, denoted as a stationary environment. If this is not the case and the distributions change between the two domains, it is called a non-stationary environment.  &lt;br /&gt;&lt;br /&gt;

The research area of Domain Adaptation offers methods to adapt the input data or an already learned decision function to the test domain data in such non-stationary environments. Current solutions search for a suitable representation space by minimizing some statistical divergence measure or subspace projector differences. The former methods bound domain differences with computational requirements almost intractable, while the latter formulate no guarantees regarding domain differences. &lt;br /&gt;&lt;br /&gt;

In the first part of this thesis, I provide geometric- and subspace-oriented projectors built upon the idea of domain separability. The methods outperform recent solutions while being a magnitude faster. Both solutions bound the domain differences by the remaining differences of the spectra, and I show that subspace solutions naturally provide less domain separability.&lt;br /&gt;&lt;br /&gt;

In the second part of this thesis, I motivated a spectral-based moment-matching regularization loss. The approach is based on the characterization of domain differences via spectral differences described above. Applied to neural networks, domains can be matched in latent or label space. Furthermore, I implemented a relevance weighting that minimizes domain-specific influences, leading to a stable and effective solution. &lt;br /&gt;&lt;br /&gt;

While the above methods work well for time-independent data with finite sample sizes, tasks such as weather forecasting require fast processing of a potentially unlimited amount of data in a temporal sequence. If the data distribution changes over time, the sequence, also called data stream, is additionally affected by Concept Drift. Domain Adaptation methods are not practical for such scenarios because they do not scale to data stream size. The research area of Concept Drift Stream Classification addresses the challenges just described. It provides a variety of algorithms and techniques to fit and adapt the model with linear complexity. Prototype-based learning is already reasonably flexible in this constraint through an online learning approach but is not yet prepared for Concept Drifts. In the third part of the thesis, I extended probabilistic prototype models by drift detection via a statistical test plus an active and passive Concept Drift adaptation, providing stable and fast concept adaptation against various drift types. 

</abstract>

<relatedItem type="constituent">
  <location>
    <url displayLabel="christoph_raab_thesis.pdf">https://pub.uni-bielefeld.de/download/2961979/2961980/christoph_raab_thesis.pdf</url>
  </location>
  <physicalDescription><internetMediaType>application/pdf</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<originInfo><publisher>Universität Bielefeld</publisher><dateIssued encoding="w3cdtf">2022</dateIssued>
</originInfo>
<language><languageTerm authority="iso639-2b" type="code">eng</languageTerm>
</language>



<relatedItem type="host"><identifier type="urn">urn:nbn:de:0070-pub-29619799</identifier><identifier type="doi">10.4119/unibi/2961979</identifier>
<part><extent unit="pages">165</extent>
</part>
</relatedItem>


<dateOther encoding="w3cdtf" type="defenseDate">2022-03-09</dateOther>
<extension>
<bibliographicCitation>
<ieee> C. Raab, &lt;em&gt;Learning in non-stationary Environments&lt;/em&gt;,  Bielefeld: Universität Bielefeld, 2022.</ieee>
<harvard1>Raab, C., 2022. &lt;em&gt;Learning in non-stationary Environments&lt;/em&gt;, Bielefeld: Universität Bielefeld.</harvard1>
<apa>Raab, C. (2022).  &lt;em&gt;Learning in non-stationary Environments&lt;/em&gt;. Bielefeld: Universität Bielefeld. &lt;a href="https://doi.org/10.4119/unibi/2961979" target="_blank"&gt;https://doi.org/10.4119/unibi/2961979&lt;/a&gt;</apa>
<frontiers>Raab, C. (2022). Learning in non-stationary Environments. Bielefeld: Universität Bielefeld.</frontiers>
<mla>Raab, Christoph. &lt;em&gt;Learning in non-stationary Environments&lt;/em&gt;. Bielefeld: Universität Bielefeld, 2022.</mla>
<apa_indent>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Raab, C. (2022).  &lt;em&gt;Learning in non-stationary Environments&lt;/em&gt;. Bielefeld: Universität Bielefeld. &lt;a href="https://doi.org/10.4119/unibi/2961979" target="_blank"&gt;https://doi.org/10.4119/unibi/2961979&lt;/a&gt;&lt;/div&gt;</apa_indent>
<wels>Raab, C. (2022): Learning in non-stationary Environments. Bielefeld: Universität Bielefeld.</wels>
<default>Raab C (2022) &lt;br /&gt;Bielefeld: Universität Bielefeld.</default>
<ama>Raab C. &lt;em&gt;Learning in non-stationary Environments&lt;/em&gt;. Bielefeld: Universität Bielefeld; 2022.</ama>
<lncs> Raab, C.: Learning in non-stationary Environments. Universität Bielefeld, Bielefeld (2022).</lncs>
<chicago>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Raab, Christoph. 2022. &lt;em&gt;Learning in non-stationary Environments&lt;/em&gt;. Bielefeld: Universität Bielefeld.&lt;/div&gt;</chicago>
<dgps>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Raab, C. (2022). &lt;em&gt;Learning in non-stationary Environments&lt;/em&gt;. Bielefeld: Universität Bielefeld. doi:10.4119/unibi/2961979.&lt;/div&gt;</dgps>
<bio1>Raab C (2022) &lt;br /&gt;&lt;em&gt;Learning in non-stationary Environments&lt;/em&gt;.&lt;br /&gt;Bielefeld: Universität Bielefeld.</bio1>
<angewandte-chemie>C.  Raab, &lt;em&gt;Learning in non-stationary Environments&lt;/em&gt;, Universität Bielefeld, Bielefeld, &lt;strong&gt;2022&lt;/strong&gt;.</angewandte-chemie>
</bibliographicCitation>
</extension>
<recordInfo><recordIdentifier>2961979</recordIdentifier><recordCreationDate encoding="w3cdtf">2022-03-24T10:23:05Z</recordCreationDate><recordChangeDate encoding="w3cdtf">2022-04-06T11:51:07Z</recordChangeDate>
</recordInfo>
</mods>