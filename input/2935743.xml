<mods xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.loc.gov/mods/v3" version="3.3" xsi:schemaLocation="http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-3-3.xsd"><id>2935743</id><setSpec>conference</setSpec><setSpec>doc-type:conferenceObject</setSpec><setSpec>ddc:004</setSpec><setSpec>conferenceFtxt</setSpec><setSpec>open_access</setSpec>

<genre>conference paper</genre>

<titleInfo><title>Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications</title></titleInfo>


<note type="publicationStatus">published</note>


<note type="qualityControlled">yes</note>

<name type="personal">
  <namePart type="given">Thomas</namePart>
  <namePart type="family">Hermann</namePart>
  <role><roleTerm type="text">author</roleTerm> </role><identifier type="local">11596</identifier><description xsi:type="identifierDefinition" type="orcid">0000-0001-7975-4363</description></name>
<name type="personal">
  <namePart type="given">Marian</namePart>
  <namePart type="family">Weger</namePart>
  <role><roleTerm type="text">author</roleTerm> </role></name>







<name type="corporate">
  <namePart/>
  <identifier type="local">8014655</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>

<name type="corporate">
  <namePart/>
  <identifier type="local">24110126</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>



<name type="conference">
  <namePart>International Conference on Auditory Display (ICAD)</namePart>
</name>






<abstract lang="eng">We introduce Auditory Contrast Enhancement (ACE) as a technique to enhance sounds at hand of a given collection of sound or sonification examples that belong to different classes, such as sounds of machines with and without a certain malfunction, or medical data sonifications for different pathologies/conditions.  A frequent use case in inductive data mining is the discovery of patterns in which such groups can be discerned, to guide subsequent paths for modelling and feature extraction.  ACE provides researchers with a set of methods to render focused auditory perspectives that accentuate inter-group differences and in turn also enhance the intra-group similarity, i.e, it warps sounds so that our human built-in metrics for assessing differences between sounds is better aligned to systematic differences between sounds belonging to different classes. We unfold and detail the concept along three different lines: temporal, spectral and spectrotemporal auditory contrast enhancement and we demonstrate their performance at hand of given sound and sonification collections.</abstract>

<relatedItem type="constituent">
  <location>
    <url displayLabel="HermannWeger-ICAD2019-ACE.pdf">https://pub.uni-bielefeld.de/download/2935743/2936197/HermannWeger-ICAD2019-ACE.pdf</url>
  </location>
  <physicalDescription><internetMediaType>application/pdf</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem><accessCondition type="use and reproduction">https://creativecommons.org/licenses/by-nc/4.0/</accessCondition>
<originInfo><publisher>ICAD</publisher><dateIssued encoding="w3cdtf">2019</dateIssued><place><placeTerm type="text">Newcastle-upon-Tyne, U.K.</placeTerm></place>
</originInfo>
<language><languageTerm authority="iso639-2b" type="code">eng</languageTerm>
</language>

<subject><topic>sonification</topic><topic>auditory display</topic><topic>sound processing</topic><topic>auditory contrast</topic>
</subject>


<relatedItem type="host"><titleInfo><title>Proceedings of the 25th International Conference on Auditory Display (ICAD 2019)</title></titleInfo><identifier type="urn">urn:nbn:de:0070-pub-29357437</identifier>
<part>
</part>
</relatedItem>
<relatedItem type="Supplementary material">
  <location>     <url>https://pub.uni-bielefeld.de/record/2935744</url>  </location>
</relatedItem>

<extension>
<bibliographicCitation>
<dgps>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Hermann, T. &amp;amp; Weger, M. (2019). Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications. &lt;em&gt;Proceedings of the 25th International Conference on Auditory Display (ICAD 2019)&lt;/em&gt;. Gehalten auf der International Conference on Auditory Display (ICAD), Newcastle: ICAD.&lt;/div&gt;</dgps>
<frontiers>Hermann, T., and Weger, M. (2019). “Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications” in &lt;em&gt;Proceedings of the 25th International Conference on Auditory Display (ICAD 2019)&lt;/em&gt; (Newcastle: ICAD).</frontiers>
<ama>Hermann T, Weger M. Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications. In:  &lt;em&gt;Proceedings of the 25th International Conference on Auditory Display (ICAD 2019)&lt;/em&gt;. Newcastle: ICAD;  2019.</ama>
<ieee> T. Hermann and M. Weger, “Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications”, &lt;em&gt;Proceedings of the 25th International Conference on Auditory Display (ICAD 2019)&lt;/em&gt;,  Newcastle: ICAD, 2019.</ieee>
<apa>Hermann, T., &amp;amp; Weger, M. (2019). Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications. &lt;em&gt;Proceedings of the 25th International Conference on Auditory Display (ICAD 2019)&lt;/em&gt; Newcastle: ICAD.</apa>
<wels>Hermann, T.; Weger, M. (2019): Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications. In: Proceedings of the 25th International Conference on Auditory Display (ICAD 2019). Newcastle: ICAD.</wels>
<angewandte-chemie>T.  Hermann, and M.  Weger, in &lt;em&gt;Proceedings of the 25th International Conference on Auditory Display (ICAD 2019)&lt;/em&gt;, Icad, Newcastle, &lt;strong&gt;2019&lt;/strong&gt;.</angewandte-chemie>
<apa_indent>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Hermann, T., &amp;amp; Weger, M. (2019). Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications. &lt;em&gt;Proceedings of the 25th International Conference on Auditory Display (ICAD 2019)&lt;/em&gt; Newcastle: ICAD.&lt;/div&gt;</apa_indent>
<bio1>Hermann T, Weger M (2019) &lt;br /&gt;Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications. &lt;br /&gt;In:  Proceedings of the 25th International Conference on Auditory Display (ICAD 2019).  Newcastle: ICAD.</bio1>
<harvard1>Hermann, T., &amp;amp; Weger, M., 2019. Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications. In &lt;em&gt;Proceedings of the 25th International Conference on Auditory Display (ICAD 2019)&lt;/em&gt;.  Newcastle: ICAD.</harvard1>
<chicago>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Hermann, Thomas, and Weger, Marian. 2019. “Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications”. In &lt;em&gt;Proceedings of the 25th International Conference on Auditory Display (ICAD 2019)&lt;/em&gt;. Newcastle: ICAD.&lt;/div&gt;</chicago>
<lncs> Hermann, T., Weger, M.: Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications. Proceedings of the 25th International Conference on Auditory Display (ICAD 2019).  ICAD, Newcastle (2019).</lncs>
<default>Hermann T, Weger M (2019)  &lt;br /&gt;In:  Proceedings of the 25th International Conference on Auditory Display (ICAD 2019). Newcastle: ICAD.</default>
<mla>Hermann, Thomas, and Weger, Marian. “Data-driven Auditory Contrast Enhancement for Everyday Sounds and Sonifications”. &lt;em&gt;Proceedings of the 25th International Conference on Auditory Display (ICAD 2019)&lt;/em&gt;. Newcastle: ICAD, 2019.</mla>
</bibliographicCitation>
</extension>
<recordInfo><recordIdentifier>2935743</recordIdentifier><recordCreationDate encoding="w3cdtf">2019-05-27T07:46:48Z</recordCreationDate><recordChangeDate encoding="w3cdtf">2020-01-30T19:43:15Z</recordChangeDate>
</recordInfo>
</mods>