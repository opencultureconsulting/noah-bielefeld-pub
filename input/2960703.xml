<mods xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.loc.gov/mods/v3" version="3.3" xsi:schemaLocation="http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-3-3.xsd"><id>2960703</id><setSpec>bi_dissertation</setSpec><setSpec>doc-type:doctoralThesis</setSpec><setSpec>ddc:004</setSpec><setSpec>bi_dissertationFtxt</setSpec><setSpec>open_access</setSpec>

<genre>thesis</genre>

<titleInfo><title>Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction</title></titleInfo>





<name type="personal">
  <namePart type="given">Dennis</namePart>
  <namePart type="family">Wobrock</namePart>
  <role><roleTerm type="text">author</roleTerm> </role><identifier type="local">54993447</identifier></name>





<name type="personal">
  
  <namePart type="given">Helge</namePart>
  
  
  <namePart type="family">Ritter</namePart>
  
  <role> <roleTerm type="text">supervisor</roleTerm> </role>
</name>



<name type="corporate">
  <namePart/>
  <identifier type="local">10038</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>








<abstract lang="eng">Since their inception, machines, computers and robots have steadily grown in complexity
to solve ever more complicated problems. For these systems of ever-growing
complexity to be usable by the largest number of people, they need to be made affordant
through tests evaluating system interactions. These tests have however shortcomings,
leaving users sometimes lost and frustrated with these systems.
In this work, we improve these interface evaluation test by relying on a Brain-Computer
Interface combining Electroencephalography with Eyetracking. We use this bi-modal
setup to provide complementary insights about a user’s perception which can be gathered
from any interaction scenario. To achieve this, we have created a set of methods
which allow our system to be applicable and informative in a variety of situations. For
scenario transposability we developed the Fixation-based Component Synchronization
method, allowing to reestablish synchronous recordings even when markers are lacking.
Using both recording modalities and the Fixation-related Potentials observable thanks to
them, we propose four different methods which provide insight into how user’s perceive
the considered interaction. These four methods are the General Difficulty via Eyetracking
(GDET) method, the Steady Peak Property Quantification (SPPQ) method, the Segment
Frequency Bands Analysis (SFBA) method and the User-dependent Potential Variation
(UdPV) method. These four methods provide respectively information about difficulties
relating to the explored environment as a whole, specific elements in the environment,
the task with which the environment is explored and specificities about the strategy with
which the user explores the environment. We discuss and test the extent of all four of
these methods in a series of three laboratory studies presenting artificial and natural interaction
scenarios. The three scenarios presents different tasks and levels of difficulty
allowing to establish the utility of these methods and verify their transposability between
situations. All proposed methods are simple to implement and offer a new way to approach
the analysis of interaction, both in a design environment and as a promising way
to create adaptive interfaces.</abstract>

<relatedItem type="constituent">
  <location>
    <url displayLabel="dwobrock_Thesis_submit.pdf">https://pub.uni-bielefeld.de/download/2960703/2960704/dwobrock_Thesis_submit.pdf</url>
  </location>
  <physicalDescription><internetMediaType>application/pdf</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<originInfo><publisher>Universität Bielefeld</publisher><dateIssued encoding="w3cdtf">2022</dateIssued>
</originInfo>
<language><languageTerm authority="iso639-2b" type="code">eng</languageTerm>
</language>



<relatedItem type="host"><identifier type="urn">urn:nbn:de:0070-pub-29607033</identifier><identifier type="doi">10.4119/unibi/2960703</identifier>
<part><extent unit="pages">210</extent>
</part>
</relatedItem>


<dateOther encoding="w3cdtf" type="defenseDate">2021-11-25</dateOther>
<extension>
<bibliographicCitation>
<dgps>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Wobrock, D. (2022). &lt;em&gt;Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction&lt;/em&gt;. Bielefeld: Universität Bielefeld. doi:10.4119/unibi/2960703.&lt;/div&gt;</dgps>
<bio1>Wobrock D (2022) &lt;br /&gt;&lt;em&gt;Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction&lt;/em&gt;.&lt;br /&gt;Bielefeld: Universität Bielefeld.</bio1>
<angewandte-chemie>D.  Wobrock, &lt;em&gt;Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction&lt;/em&gt;, Universität Bielefeld, Bielefeld, &lt;strong&gt;2022&lt;/strong&gt;.</angewandte-chemie>
<ama>Wobrock D. &lt;em&gt;Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction&lt;/em&gt;. Bielefeld: Universität Bielefeld; 2022.</ama>
<chicago>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Wobrock, Dennis. 2022. &lt;em&gt;Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction&lt;/em&gt;. Bielefeld: Universität Bielefeld.&lt;/div&gt;</chicago>
<lncs> Wobrock, D.: Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction. Universität Bielefeld, Bielefeld (2022).</lncs>
<wels>Wobrock, D. (2022): Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction. Bielefeld: Universität Bielefeld.</wels>
<frontiers>Wobrock, D. (2022). Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction. Bielefeld: Universität Bielefeld.</frontiers>
<mla>Wobrock, Dennis. &lt;em&gt;Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction&lt;/em&gt;. Bielefeld: Universität Bielefeld, 2022.</mla>
<apa_indent>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Wobrock, D. (2022).  &lt;em&gt;Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction&lt;/em&gt;. Bielefeld: Universität Bielefeld. &lt;a href="https://doi.org/10.4119/unibi/2960703" target="_blank"&gt;https://doi.org/10.4119/unibi/2960703&lt;/a&gt;&lt;/div&gt;</apa_indent>
<default>Wobrock D (2022) &lt;br /&gt;Bielefeld: Universität Bielefeld.</default>
<ieee> D. Wobrock, &lt;em&gt;Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction&lt;/em&gt;,  Bielefeld: Universität Bielefeld, 2022.</ieee>
<harvard1>Wobrock, D., 2022. &lt;em&gt;Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction&lt;/em&gt;, Bielefeld: Universität Bielefeld.</harvard1>
<apa>Wobrock, D. (2022).  &lt;em&gt;Combined analysis of Electroencephalography and eyetracking to create new windows into cognitive human-machine interaction&lt;/em&gt;. Bielefeld: Universität Bielefeld. &lt;a href="https://doi.org/10.4119/unibi/2960703" target="_blank"&gt;https://doi.org/10.4119/unibi/2960703&lt;/a&gt;</apa>
</bibliographicCitation>
</extension>
<recordInfo><recordIdentifier>2960703</recordIdentifier><recordCreationDate encoding="w3cdtf">2022-01-24T08:47:05Z</recordCreationDate><recordChangeDate encoding="w3cdtf">2022-01-27T10:59:24Z</recordChangeDate>
</recordInfo>
</mods>