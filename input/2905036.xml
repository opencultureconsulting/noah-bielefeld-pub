<mods xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.loc.gov/mods/v3" version="3.3" xsi:schemaLocation="http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-3-3.xsd"><id>2905036</id><setSpec>conference</setSpec><setSpec>doc-type:conferenceObject</setSpec><setSpec>ddc:004</setSpec><setSpec>conferenceFtxt</setSpec><setSpec>open_access</setSpec>

<genre>conference paper</genre>

<titleInfo><title>EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions</title></titleInfo>




<note type="qualityControlled">yes</note>

<name type="personal">
  <namePart type="given">Thomas</namePart>
  <namePart type="family">Hermann</namePart>
  <role><roleTerm type="text">author</roleTerm> </role><identifier type="local">11596</identifier><description xsi:type="identifierDefinition" type="orcid">0000-0001-7975-4363</description></name>
<name type="personal">
  <namePart type="given">Jiajun</namePart>
  <namePart type="family">Yang</namePart>
  <role><roleTerm type="text">author</roleTerm> </role><identifier type="local">63510689</identifier></name>
<name type="personal">
  <namePart type="given">Yukie</namePart>
  <namePart type="family">Nagai</namePart>
  <role><roleTerm type="text">author</roleTerm> </role></name>







<name type="corporate">
  <namePart/>
  <identifier type="local">8014655</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>

<name type="corporate">
  <namePart/>
  <identifier type="local">24110126</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>



<name type="conference">
  <namePart>Audio Mostly 2016</namePart>
</name>



<name type="corporate">
  <namePart>Thematic Network Interactive Intelligent Systems</namePart>
  <role><roleTerm type="text">project</roleTerm></role>
</name>



<abstract lang="eng">This paper presents a novel approach for using sound to externalize emotional states so that they become an object for communication and reflection both for the users themselves and for interaction with other users such as peers, parents or therapists. We present an abstract, vocal, and physiology-based sound synthesis model whose sound space each covers various emotional associations. The key idea in our approach is to use an evolutionary optimization approach to enable users to find emotional prototypes which are then in turn fed into a kernel-regression-based mapping to allow users to navigate the sound space via a low-dimensional interface, which can be controlled in a playful way via tablet interactions. The method is intended to be used for supporting people with autism spectrum disorder.</abstract>

<relatedItem type="constituent">
  <location>
    <url displayLabel="HermannYN2016-EIS.pdf">https://pub.uni-bielefeld.de/download/2905036/2909480/HermannYN2016-EIS.pdf</url>
  </location>
  <physicalDescription><internetMediaType>application/pdf</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<originInfo><dateIssued encoding="w3cdtf">2016</dateIssued><place><placeTerm type="text">Norrköping, Sweden</placeTerm></place>
</originInfo>
<language><languageTerm authority="iso639-2b" type="code">eng</languageTerm>
</language>

<subject><topic>Emotions</topic><topic>Sound</topic><topic>Auditory Display</topic><topic>Autism Spectrum Disorder (ASD)</topic>
</subject>


<relatedItem type="host"><identifier type="urn">urn:nbn:de:0070-pub-29050360</identifier><identifier type="doi">10.1145/2986416.2986437</identifier>
<part>
</part>
</relatedItem>
<relatedItem type="Supplementary material">
  <location>     <url>https://pub.uni-bielefeld.de/record/2905039</url>  </location>
</relatedItem>

<extension>
<bibliographicCitation>
<frontiers>Hermann, T., Yang, J., and Nagai, Y. (2016).“EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions”. Presented at the Audio Mostly 2016, Norrköping, Sweden.</frontiers>
<dgps>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Hermann, T., Yang, J. &amp;amp; Nagai, Y. (2016). EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions. Gehalten auf der Audio Mostly 2016. doi:10.1145/2986416.2986437.&lt;/div&gt;</dgps>
<ama>Hermann T, Yang J, Nagai Y. EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions. Presented at the Audio Mostly 2016, Norrköping, Sweden.</ama>
<ieee> T. Hermann, J. Yang, and Y. Nagai, “EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions”, Presented at the Audio Mostly 2016, Norrköping, Sweden, 2016.</ieee>
<apa>Hermann, T., Yang, J., &amp;amp; Nagai, Y. (2016). &lt;em&gt;EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions&lt;/em&gt;. Presented at the Audio Mostly 2016, Norrköping, Sweden. doi:10.1145/2986416.2986437</apa>
<wels>Hermann, T.; Yang, J.; Nagai, Y. (2016): EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions.</wels>
<angewandte-chemie>T.  Hermann, J.  Yang, and Y.  Nagai, &lt;strong&gt;2016&lt;/strong&gt;.</angewandte-chemie>
<harvard1>Hermann, T., Yang, J., &amp;amp; Nagai, Y., 2016. EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions. Presented at the Audio Mostly 2016, Norrköping, Sweden.</harvard1>
<bio1>Hermann T, Yang J, Nagai Y (2016) &lt;br /&gt;EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions. &lt;br /&gt;Presented at the Audio Mostly 2016, Norrköping, Sweden.</bio1>
<apa_indent>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Hermann, T., Yang, J., &amp;amp; Nagai, Y. (2016). &lt;em&gt;EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions&lt;/em&gt;. Presented at the Audio Mostly 2016, Norrköping, Sweden. doi:10.1145/2986416.2986437&lt;/div&gt;</apa_indent>
<chicago>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Hermann, Thomas, Yang, Jiajun, and Nagai, Yukie. 2016. “EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions”. Presented at the Audio Mostly 2016, Norrköping, Sweden .&lt;/div&gt;</chicago>
<lncs> Hermann, T., Yang, J., Nagai, Y.: EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions. Presented at the Audio Mostly 2016, Norrköping, Sweden (2016).</lncs>
<default>Hermann T, Yang J, Nagai Y (2016)  &lt;br /&gt;Presented at the Audio Mostly 2016, Norrköping, Sweden.</default>
<mla>Hermann, Thomas, Yang, Jiajun, and Nagai, Yukie. “EmoSonics – Interactive Sound Interfaces for the Externalization of Emotions”. Presented at the Audio Mostly 2016, Norrköping, Sweden, 2016.</mla>
</bibliographicCitation>
</extension>
<recordInfo><recordIdentifier>2905036</recordIdentifier><recordCreationDate encoding="w3cdtf">2016-08-08T14:21:43Z</recordCreationDate><recordChangeDate encoding="w3cdtf">2021-11-10T12:55:02Z</recordChangeDate>
</recordInfo>
</mods>