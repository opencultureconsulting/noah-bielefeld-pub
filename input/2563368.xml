<mods xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.loc.gov/mods/v3" version="3.3" xsi:schemaLocation="http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-3-3.xsd"><id>2563368</id><setSpec>bi_dissertation</setSpec><setSpec>doc-type:doctoralThesis</setSpec><setSpec>ddc:000</setSpec><setSpec>bi_dissertationFtxt</setSpec><setSpec>open_access</setSpec>

<genre>thesis</genre>

<titleInfo><title>Random center- surround approaches for modeling visual saliency</title></titleInfo>





<name type="personal">
  <namePart type="given">Vikram</namePart>
  <namePart type="family">Narayan</namePart>
  <role><roleTerm type="text">author</roleTerm> </role><identifier type="local">18267899</identifier></name>





<name type="personal">
  
  <namePart type="given">Britta</namePart>
  
  
  <namePart type="family">Wrede</namePart>
  
  <role> <roleTerm type="text">supervisor</roleTerm> </role>
</name>



<name type="corporate">
  <namePart/>
  <identifier type="local">18304588</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>

<name type="corporate">
  <namePart/>
  <identifier type="local">8014655</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>








<abstract lang="eng">Computational models of visual saliency have been used to detect salient regions and simulate human eye-gaze on images and videos.
A majority of the existing approaches are highly parametric in nature.
They are specialized to predict either eye-gaze or detect salient
regions, but not both simultaneously. Like other computer vision approaches,
the saliency models too impose pre-specified grids to process
the image. In this context we explore ways of exploiting random/
stochastic algorithmic approaches for saliency computation to
address issues like pre-specified grids, computational efficiency, parameter
set etc. We propose three different approaches for saliency
computation on images and provide elaborate benchmarking results
with respect to other saliency systems. Consequently, we have been
successful in improving the state-of-the-art in terms of eye-gaze prediction
and salient region detection performance of the saliency systems.
In addition, we have extended one of our proposed saliency
approaches to predict eye-gaze while viewing a tutoring or goaldirected
action scenario. Along with the proposed algorithms, we
also have created a video dataset for evaluating saliency systems in
the context of goal-directed action. We hope that the proposed approaches
for saliency computation, exprimental protocols, resulting
video dataset and the ensuing discussions will help the community
in developing more sophisticated systems of visual saliency.</abstract>

<relatedItem type="constituent">
  <location>
    <url displayLabel="Vikram_Thesis.pdf">https://pub.uni-bielefeld.de/download/2563368/2563369/Vikram_Thesis.pdf</url>
  </location>
  <physicalDescription><internetMediaType>application/pdf</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<originInfo><publisher>Universitätsbibliothek</publisher><dateIssued encoding="w3cdtf">2013</dateIssued>
</originInfo>
<language><languageTerm authority="iso639-2b" type="code">eng</languageTerm>
</language>



<relatedItem type="host"><identifier type="urn">urn:nbn:de:hbz:361-25633684</identifier>
<part>
</part>
</relatedItem>


<dateOther encoding="w3cdtf" type="defenseDate">2013-03-14</dateOther>
<extension>
<bibliographicCitation>
<apa>Narayan, V. (2013).  &lt;em&gt;Random center- surround approaches for modeling visual saliency&lt;/em&gt;. Bielefeld: Universitätsbibliothek.</apa>
<ieee> V. Narayan, &lt;em&gt;Random center- surround approaches for modeling visual saliency&lt;/em&gt;,  Bielefeld: Universitätsbibliothek, 2013.</ieee>
<ama>Narayan V. &lt;em&gt;Random center- surround approaches for modeling visual saliency&lt;/em&gt;. Bielefeld: Universitätsbibliothek; 2013.</ama>
<frontiers>Narayan, V. (2013). Random center- surround approaches for modeling visual saliency. Bielefeld: Universitätsbibliothek.</frontiers>
<dgps>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Narayan, V. (2013). &lt;em&gt;Random center- surround approaches for modeling visual saliency&lt;/em&gt;. Bielefeld: Universitätsbibliothek.&lt;/div&gt;</dgps>
<bio1>Narayan V (2013) &lt;br /&gt;&lt;em&gt;Random center- surround approaches for modeling visual saliency&lt;/em&gt;.&lt;br /&gt;Bielefeld: Universitätsbibliothek.</bio1>
<apa_indent>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Narayan, V. (2013).  &lt;em&gt;Random center- surround approaches for modeling visual saliency&lt;/em&gt;. Bielefeld: Universitätsbibliothek.&lt;/div&gt;</apa_indent>
<harvard1>Narayan, V., 2013. &lt;em&gt;Random center- surround approaches for modeling visual saliency&lt;/em&gt;, Bielefeld: Universitätsbibliothek.</harvard1>
<angewandte-chemie>V.  Narayan, &lt;em&gt;Random center- surround approaches for modeling visual saliency&lt;/em&gt;, Universitätsbibliothek, Bielefeld, &lt;strong&gt;2013&lt;/strong&gt;.</angewandte-chemie>
<wels>Narayan, V. (2013): Random center- surround approaches for modeling visual saliency. Bielefeld: Universitätsbibliothek.</wels>
<mla>Narayan, Vikram. &lt;em&gt;Random center- surround approaches for modeling visual saliency&lt;/em&gt;. Bielefeld: Universitätsbibliothek, 2013.</mla>
<default>Narayan V (2013) &lt;br /&gt;Bielefeld: Universitätsbibliothek.</default>
<lncs> Narayan, V.: Random center- surround approaches for modeling visual saliency. Universitätsbibliothek, Bielefeld (2013).</lncs>
<chicago>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Narayan, Vikram. 2013. &lt;em&gt;Random center- surround approaches for modeling visual saliency&lt;/em&gt;. Bielefeld: Universitätsbibliothek.&lt;/div&gt;</chicago>
</bibliographicCitation>
</extension>
<recordInfo><recordIdentifier>2563368</recordIdentifier><recordCreationDate encoding="w3cdtf">2013-03-25T14:05:13Z</recordCreationDate><recordChangeDate encoding="w3cdtf">2018-07-24T13:01:21Z</recordChangeDate>
</recordInfo>
</mods>