<mods xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.loc.gov/mods/v3" version="3.3" xsi:schemaLocation="http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-3-3.xsd"><id>2652246</id><setSpec>conference</setSpec><setSpec>doc-type:conferenceObject</setSpec><setSpec>ddc:000</setSpec><setSpec>conferenceFtxt</setSpec><setSpec>open_access</setSpec>

<genre>conference paper</genre>

<titleInfo><title>EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology</title></titleInfo>


<note type="publicationStatus">published</note>


<note type="qualityControlled">yes</note>

<name type="personal">
  <namePart type="given">Thies</namePart>
  <namePart type="family">Pfeiffer</namePart>
  <role><roleTerm type="text">author</roleTerm> </role><identifier type="local">182991</identifier><description xsi:type="identifierDefinition" type="orcid">0000-0001-6619-749X</description></name>
<name type="personal">
  <namePart type="given">Patrick</namePart>
  <namePart type="family">Renner</namePart>
  <role><roleTerm type="text">author</roleTerm> </role><identifier type="local">39272387</identifier><description xsi:type="identifierDefinition" type="orcid">0000-0002-9640-8291</description></name>







<name type="corporate">
  <namePart/>
  <identifier type="local">10044</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>

<name type="corporate">
  <namePart/>
  <identifier type="local">27003888</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>

<name type="corporate">
  <namePart/>
  <identifier type="local">8014655</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>

<name type="corporate">
  <namePart/>
  <identifier type="local">27015432</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>








<abstract lang="eng">For validly analyzing human visual attention, it is often necessary to proceed from computer-based desktop set-ups to more natural real-world settings. However, the resulting loss of control has to be counterbalanced by increasing 
participant and/or item count. Together with the effort required to manually annotate the gaze-cursor videos recorded with mobile eye trackers, this renders many studies unfeasible.

We tackle this issue by minimizing the need for manual annotation of mobile gaze data. Our approach combines geo\-metric modelling with inexpensive 3D marker tracking to align virtual proxies with the real-world objects. This allows us to classify fixations on objects of interest automatically while supporting a completely free moving participant.

The paper presents the EyeSee3D method as well as a comparison of an expensive outside-in (external cameras) and a low-cost inside-out (scene camera) tracking of the eyetracker's position. The EyeSee3D approach is evaluated comparing the results from automatic and manual classification of fixation targets, which raises old problems of annotation validity in a modern context.</abstract>

<relatedItem type="constituent">
  <location>
    <url displayLabel="etra_full_paper_194_final.pdf">https://pub.uni-bielefeld.de/download/2652246/2653372/etra_full_paper_194_final.pdf</url>
  </location>
  <physicalDescription><internetMediaType>application/pdf</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<relatedItem type="constituent">
  <location>
    <url displayLabel="EyeSee3D_Poster.pdf">https://pub.uni-bielefeld.de/download/2652246/2666077/EyeSee3D_Poster.pdf</url>
  </location>
  <physicalDescription><internetMediaType>application/pdf</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<originInfo><publisher>ACM</publisher><dateIssued encoding="w3cdtf">2014</dateIssued>
</originInfo>
<language><languageTerm authority="iso639-2b" type="code">eng</languageTerm>
</language>

<subject><topic>Gaze-based InteractionEyetrackingAugmented Reality</topic>
</subject>


<relatedItem type="host"><titleInfo><title>Proceedings of the Symposium on Eye Tracking Research and Applications</title></titleInfo>
  <identifier type="isbn">978-1-4503-2751-0</identifier><identifier type="urn">urn:nbn:de:0070-pub-26522467</identifier><identifier type="doi">10.1145/2578153.2578183</identifier>
<part><extent unit="pages">195-202</extent>
</part>
</relatedItem>


<extension>
<bibliographicCitation>
<bio1>Pfeiffer T, Renner P (2014) &lt;br /&gt;EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology. &lt;br /&gt;In:  Proceedings of the Symposium on Eye Tracking Research and Applications.  New York: ACM:  195-202.</bio1>
<apa_indent>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Pfeiffer, T., &amp;amp; Renner, P. (2014). EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology. &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;, 195-202. New York: ACM. doi:10.1145/2578153.2578183&lt;/div&gt;</apa_indent>
<harvard1>Pfeiffer, T., &amp;amp; Renner, P., 2014. EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology. In &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;.  New York: ACM, pp. 195-202.</harvard1>
<angewandte-chemie>T.  Pfeiffer, and P.  Renner, in &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;, Acm, New York, &lt;strong&gt;2014&lt;/strong&gt;, p. 195-202.</angewandte-chemie>
<wels>Pfeiffer, T.; Renner, P. (2014): EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology. In: Proceedings of the Symposium on Eye Tracking Research and Applications. New York: ACM.  S. 195-202.</wels>
<apa>Pfeiffer, T., &amp;amp; Renner, P. (2014). EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology. &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;, 195-202. New York: ACM. doi:10.1145/2578153.2578183</apa>
<ieee> T. Pfeiffer and P. Renner, “EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology”, &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;,  New York: ACM, 2014,  pp.195-202.</ieee>
<ama>Pfeiffer T, Renner P. EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology. In:  &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;. New York: ACM;  2014: 195-202.</ama>
<frontiers>Pfeiffer, T., and Renner, P. (2014). “EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology” in &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt; (New York: ACM), 195-202.</frontiers>
<dgps>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Pfeiffer, T. &amp;amp; Renner, P. (2014). EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology. &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt; (S. 195-202). New York: ACM. doi:10.1145/2578153.2578183.&lt;/div&gt;</dgps>
<mla>Pfeiffer, Thies, and Renner, Patrick. “EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology”. &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;. New York: ACM, 2014. 195-202.</mla>
<default>Pfeiffer T, Renner P (2014)  &lt;br /&gt;In:  Proceedings of the Symposium on Eye Tracking Research and Applications. New York: ACM:  195-202.</default>
<lncs> Pfeiffer, T., Renner, P.: EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology. Proceedings of the Symposium on Eye Tracking Research and Applications. p. 195-202. ACM, New York (2014).</lncs>
<chicago>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Pfeiffer, Thies, and Renner, Patrick. 2014. “EyeSee3D: a low-cost approach for analysing mobile 3D eye tracking data using augmented reality technology”. In &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;, 195-202. New York: ACM.&lt;/div&gt;</chicago>
</bibliographicCitation>
</extension>
<recordInfo><recordIdentifier>2652246</recordIdentifier><recordCreationDate encoding="w3cdtf">2014-01-29T16:34:17Z</recordCreationDate><recordChangeDate encoding="w3cdtf">2019-10-22T16:48:49Z</recordChangeDate>
</recordInfo>
</mods>