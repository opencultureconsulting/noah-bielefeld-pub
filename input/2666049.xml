<mods xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.loc.gov/mods/v3" version="3.3" xsi:schemaLocation="http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-3-3.xsd"><id>2666049</id><setSpec>conference</setSpec><setSpec>doc-type:conferenceObject</setSpec><setSpec>ddc:000</setSpec><setSpec>conferenceFtxt</setSpec><setSpec>open_access</setSpec>

<genre>conference paper</genre>

<titleInfo><title>Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction</title></titleInfo>


<note type="publicationStatus">published</note>


<note type="qualityControlled">yes</note>

<name type="personal">
  <namePart type="given">Patrick</namePart>
  <namePart type="family">Renner</namePart>
  <role><roleTerm type="text">author</roleTerm> </role><identifier type="local">39272387</identifier><description xsi:type="identifierDefinition" type="orcid">0000-0002-9640-8291</description></name>
<name type="personal">
  <namePart type="given">Thies</namePart>
  <namePart type="family">Pfeiffer</namePart>
  <role><roleTerm type="text">author</roleTerm> </role><identifier type="local">182991</identifier><description xsi:type="identifierDefinition" type="orcid">0000-0001-6619-749X</description></name>







<name type="corporate">
  <namePart/>
  <identifier type="local">27015432</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>

<name type="corporate">
  <namePart/>
  <identifier type="local">10044</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>

<name type="corporate">
  <namePart/>
  <identifier type="local">8014655</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>








<abstract lang="eng">For solving complex tasks cooperatively in close interaction with robots, they need to understand natural human communication. To achieve this, robots could benefit from a deeper understanding of the processes that humans use for successful communication. Such skills can be studied by investigating human face-to-face interactions in complex tasks. In our work the focus lies on shared-space interactions in a path planning task and thus 3D gaze directions and hand movements are of particular interest. However, the analysis of gaze and gestures is a time-consuming task: Usually, manual annotation of the eye tracker's scene camera video is necessary in a frame-by-frame manner. To tackle this issue, based on the EyeSee3D method, an automatic approach for annotating interactions is presented: A combination of geometric modeling and 3D marker tracking serves to align real world stimuli with virtual proxies. This is done based on the scene camera images of the mobile eye tracker alone. In addition to the EyeSee3D approach, face detection is used to automatically detect fixations on the interlocutor. For the acquisition of the gestures, an optical marker tracking system is integrated and fused in the multimodal representation of the communicative situation.</abstract>

<relatedItem type="constituent">
  <location>
    <url displayLabel="ModelBasedAcquisition.pdf">https://pub.uni-bielefeld.de/download/2666049/2666062/ModelBasedAcquisition.pdf</url>
  </location>
  <physicalDescription><internetMediaType>application/pdf</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<relatedItem type="constituent">
  <location>
    <url displayLabel="Analysing_Human_Face-to-Face_Interactions_in_Shared_Space.pdf">https://pub.uni-bielefeld.de/download/2666049/2666073/Analysing_Human_Face-to-Face_Interactions_in_Shared_Space.pdf</url>
  </location>
  <physicalDescription><internetMediaType>application/pdf</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<originInfo><publisher>ACM</publisher><dateIssued encoding="w3cdtf">2014</dateIssued>
</originInfo>
<language><languageTerm authority="iso639-2b" type="code">eng</languageTerm>
</language>

<subject><topic>Eyetracking</topic><topic>geometric modelling</topic><topic>motion tracking</topic><topic>Gaze-based Interaction</topic><topic>3D gaze analysis</topic><topic>Augmented Reality</topic><topic>eye tracking</topic><topic>marker tracking</topic>
</subject>


<relatedItem type="host"><titleInfo><title>Proceedings of the Symposium on Eye Tracking Research and Applications</title></titleInfo>
  <identifier type="isbn">978-1-4503-2751-0</identifier><identifier type="urn">urn:nbn:de:0070-pub-26660493</identifier><identifier type="doi">10.1145/2578153.2582176</identifier>
<part><extent unit="pages">361-362</extent>
</part>
</relatedItem>


<extension>
<bibliographicCitation>
<mla>Renner, Patrick, and Pfeiffer, Thies. “Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction”. &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;. New York, NY, USA: ACM, 2014. ETRA '14. 361-362.</mla>
<default>Renner P, Pfeiffer T (2014)  &lt;br /&gt;In:  Proceedings of the Symposium on Eye Tracking Research and Applications. ETRA '14.  New York, NY, USA: ACM:  361-362.</default>
<lncs> Renner, P., Pfeiffer, T.: Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction. Proceedings of the Symposium on Eye Tracking Research and Applications. ETRA '14. p. 361-362. ACM, New York, NY, USA (2014).</lncs>
<chicago>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Renner, Patrick, and Pfeiffer, Thies. 2014. “Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction”. In &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;, 361-362. ETRA '14. New York, NY, USA: ACM.&lt;/div&gt;</chicago>
<harvard1>Renner, P., &amp;amp; Pfeiffer, T., 2014. Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction. In &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;. ETRA '14.  New York, NY, USA: ACM, pp. 361-362.</harvard1>
<apa_indent>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Renner, P., &amp;amp; Pfeiffer, T. (2014). Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction. &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;, ETRA '14, 361-362. New York, NY, USA: ACM. doi:10.1145/2578153.2582176&lt;/div&gt;</apa_indent>
<bio1>Renner P, Pfeiffer T (2014) &lt;br /&gt;Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction. &lt;br /&gt;In:  Proceedings of the Symposium on Eye Tracking Research and Applications.  ETRA '14,  New York, NY, USA: ACM:  361-362.</bio1>
<angewandte-chemie>P.  Renner, and T.  Pfeiffer, in &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;, Acm, New York, NY, USA, &lt;strong&gt;2014&lt;/strong&gt;, p. 361-362.</angewandte-chemie>
<wels>Renner, P.; Pfeiffer, T. (2014): Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction. In: Proceedings of the Symposium on Eye Tracking Research and Applications. New York, NY, USA: ACM. (ETRA '14, ).  S. 361-362.</wels>
<apa>Renner, P., &amp;amp; Pfeiffer, T. (2014). Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction. &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;, ETRA '14, 361-362. New York, NY, USA: ACM. doi:10.1145/2578153.2582176</apa>
<ieee> P. Renner and T. Pfeiffer, “Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction”, &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;, ETRA '14,  New York, NY, USA: ACM, 2014,  pp.361-362.</ieee>
<ama>Renner P, Pfeiffer T. Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction. In:  &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt;. ETRA '14. New York, NY, USA: ACM;  2014: 361-362.</ama>
<frontiers>Renner, P., and Pfeiffer, T. (2014). “Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction” in &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt; ETRA '14 (New York, NY, USA: ACM), 361-362.</frontiers>
<dgps>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Renner, P. &amp;amp; Pfeiffer, T. (2014). Model-based acquisition and analysis of multimodal interactions for improving human-robot interaction (ETRA '14). &lt;em&gt;Proceedings of the Symposium on Eye Tracking Research and Applications&lt;/em&gt; (S. 361-362). New York, NY, USA: ACM. doi:10.1145/2578153.2582176.&lt;/div&gt;</dgps>
</bibliographicCitation>
</extension>
<recordInfo><recordIdentifier>2666049</recordIdentifier><recordCreationDate encoding="w3cdtf">2014-03-29T19:01:39Z</recordCreationDate><recordChangeDate encoding="w3cdtf">2018-07-24T13:01:01Z</recordChangeDate>
</recordInfo>
</mods>