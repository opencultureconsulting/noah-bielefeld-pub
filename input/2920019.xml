<mods xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.loc.gov/mods/v3" version="3.3" xsi:schemaLocation="http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-3-3.xsd"><id>2920019</id><setSpec>bi_dissertation</setSpec><setSpec>doc-type:doctoralThesis</setSpec><setSpec>ddc:410</setSpec><setSpec>bi_dissertationFtxt</setSpec><setSpec>open_access</setSpec>

<genre>thesis</genre>

<titleInfo><title>The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing</title></titleInfo>





<name type="personal">
  <namePart type="given">Alba</namePart>
  <namePart type="family">Rodríguez</namePart>
  <role><roleTerm type="text">author</roleTerm> </role></name>





<name type="personal">
  
  <namePart type="given">Pia</namePart>
  
  
  <namePart type="family">Knoeferle</namePart>
  
  <role> <roleTerm type="text">supervisor</roleTerm> </role>
</name>



<name type="corporate">
  <namePart/>
  <identifier type="local">10019</identifier>
  <role>
    <roleTerm type="text">department</roleTerm>
  </role>
</name>








<abstract lang="eng">Studies on situated language comprehension (i.e., comprehension in rich visual contexts), have shown that the comprehender makes use of different information sources in order to establish visual reference and to visually anticipate entities in a scene while understanding language (reflecting expectations on what might be mentioned next). Semantics and world-knowledge (i.e., experiential, long-term knowledge) are among these sources. For instance, when listening to a sentence like *The girl will ride...*, the comprehender will likely anticipate an object that a girl could ride, e.g., a carrousel, rather than other objects, such as a motorbike (Kamide, Altmann, &amp; Haywood, 2003). However, following the inspection of events (featuring agents acting upon objects or patients), comprehenders have so far shown a preference to visually anticipate the agents or objects that have been seen as part of    those prior events (i.e., *recent-event preference* or the preference for event-based representations; Abashidze, Carminati, &amp; Knoeferle, 2014; Knoeferle, Carminati, Abashidze, &amp; Essig, 2011). This preference emerged even when other plausible objects or better stereotypically fitting agents were present. Although the preference for event-based information over other sources (e.g., plausibility or stereotypicality) seems to be strong and has been accommodated in accounts of situated language comprehension (Knoeferle &amp; Crocker, 2006, 2007), its nature when comprehenders generate expectations is still unspecified. Crucially, the preference for recent events has not been generalized from action events to other types of information in the visual and linguistic contexts. &lt;br /&gt;To further examine this issue, this thesis investigated the role of a particular type of information during situated language comprehension under the influence of prior events, namely, visual gender and action cues and knowledge about gender stereotypes. As many studies in the field of psycholinguistics have highlighted, gender (both a biological and a social feature of human beings) is relevant in language comprehension (e.g., grammatical gender can serve to track reference in discourse, and gender-stereotype knowledge can bias our interpretation of a sentence). However, little psycholinguistic research has examined the comprehension of gender information in a visual context. We argue that gender is worth exploring in a paradigm where prior event representations can be pitted against long-term knowledge. Not only that, inspired by experiments using mismatch designs, we wanted to see how the visual attention of the comprehender might be affected as a function of referential incongruencies (i.e., mismatches between visual events and linguistic information, e.g., Knoeferle, Urbach, &amp; Kutas, 2014; Vissers, Kolk, Van de Meerendonk, &amp; Chwilla, 2008; Wassenaar &amp; Hagoort, 2007) and incongruences at the level of worldknowledge (i.e., gender stereotypes; e.g., Duffy &amp; Keir, 2004; Kreiner, Sturt, &amp; Garrod, 2008). By doing so, we could get insights into how both types of sources (event-based information and gender-stereotype knowledge from language) are used, i.e., whether one is more important than the other or if both are equally exploited in situated language comprehension. &lt;br /&gt;We conducted three eye-tracking, visual-world experiments and one EEG experiment. In all of these experiments, participants saw events taking place prior to sentence comprehension, i.e., videos of (female or male) hands acting upon objects. In the eye-tracking experiments, following the videos, a visual scene appeared with the faces of two potential agents: one male and one female1. While the agent matching the gender features from prior events (i.e., the hands) was considered as the target agent, the other potential agent, whose gender was not cued in previous events, was the competitor agent. The visual scene in Experiment 3 further included the images of two objects; one was the target object (i.e., the object that appeared in prior events), while the other was a competitor object with opposite stereotypical valence. During the presentation of this scene, an OVS sentence was presented (e.g., translation from German: ‘The cakeNP1/obj bakesV soonADV SusannaNP2/subj’). We used the non-canonical OVS word order as opposed to SVO (more commonly used in prior research, e.g., Knoeferle, Carminati, et al., 2011) precisely to examine participants’ expectations towards the agent, who was mentioned at final position. We manipulated two factors. One factor was the match between prior visual events and language: there were action-verb(-phrase) mismatches in Experiments 1 and 3, and mismatches between the gender of the hands and the final subject (i.e., the proper name) in Experiments 2 and 4. The second manipulation, present in Experiments 1 to 3, was the match between the stereotypical valence of the described actions/events in the sentence and the target agent’s gender. In the eye-tracking experiments, we measured participants’ visual attention towards the agents’ faces during sentence comprehension. In the EEG experiment, we measured ERP responses time-locked to the final, proper name region (i.e., Susanna). Participants’ task was to verify via button press whether the sentence matched the events they just saw. &lt;br /&gt;In line with prior research, our results support the idea that the preference for eventbased representations generalizes to another cue, i.e., gender features from the hands of an agent during prior events. Participants generally preferred to look at the target agent compared to the competitor. These results also suggest that the recent-event preference does not just rely on representations of full objects, agents and events, but also subtler (gender) features that serve to identify feature-matching targets during comprehension (i.e., faces of agents are inspected based on the gender features from hands seen in prior events). This preference is however modulated by mismatches in language, i.e., whenever the actions described or the gender implied by the final noun in the sentence were at odds with prior events, attention towards the target agent was reduced. In addition, the scene configuration of Experiment 3 gave rise to gender stereotypicality effects, which had not yet been found in prior studies using a similar design. Participants looked at the target agent (vs. the competitor) to a greater extent when the action described by the sentence stereotypically matched (vs. mismatched) them. As for the electrophysiological response towards mismatches between event-based gender cues and language, we found a biphasic ERP response, which suggests that this type of verification requires two semantically-induced stages of processing. This response had commonalities both with some effects found in strictly linguistic/discourse contexts but also with previously observed mismatch effects in picture-sentence verification studies (i.e., role relation and action mismatches; Knoeferle et al., 2014), which suggests that a similar (perhaps a single) processing mechanism might be involved in several visuolinguistic relations. &lt;br /&gt;In sum, our results using gender and action cues from prior events and long-term knowledge call for a more refined consideration of the different aspects involved in (situated) language comprehension. On the one hand, existing accounts need to accommodate further reconciliations/verifications of visuolinguistic relations (e.g., roles, actions, gender features, etc.). When it comes to listeners generating expectations during comprehension while inspecting the visual world, we further suggest that a weighted system (i.e., a system indexing the strength of the expectation and how different information sources contribute to it; also suggested in Münster, 2016), applies for gender of information. Not only event-based representations, but also different discrepancies between these representations and language and, depending on the concurrent visual scene configuration, long-term knowledge (e.g., pertaining to gender stereotypes), can affect weighted expectations. Biosocial aspects such as gender may be of particular interest to answer some of the open questions in how situated language comprehension works, as these aspects can be found and manipulated at different levels of communication (e.g., the comprehender, the speaker, the linguistic content, etc.).</abstract>

<relatedItem type="constituent">
  <location>
    <url displayLabel="Rodriguez_Alba_PhDThesis_2018_.pdf">https://pub.uni-bielefeld.de/download/2920019/2920399/Rodriguez_Alba_PhDThesis_2018_.pdf</url>
  </location>
  <physicalDescription><internetMediaType>application/pdf</internetMediaType></physicalDescription>
  <accessCondition type="restrictionOnAccess">no</accessCondition>
</relatedItem>
<originInfo><publisher>Universität Bielefeld</publisher><dateIssued encoding="w3cdtf">2018</dateIssued>
</originInfo>
<language><languageTerm authority="iso639-2b" type="code">eng</languageTerm>
</language>



<relatedItem type="host"><identifier type="urn">urn:nbn:de:0070-pub-29200198</identifier>
<part>
</part>
</relatedItem>


<dateOther encoding="w3cdtf" type="defenseDate">2018-02-23</dateOther>
<extension>
<bibliographicCitation>
<mla>Rodríguez, Alba. &lt;em&gt;The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing&lt;/em&gt;. Bielefeld: Universität Bielefeld, 2018.</mla>
<default>Rodríguez A (2018) &lt;br /&gt;Bielefeld: Universität Bielefeld.</default>
<lncs> Rodríguez, A.: The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing. Universität Bielefeld, Bielefeld (2018).</lncs>
<chicago>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Rodríguez, Alba. 2018. &lt;em&gt;The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing&lt;/em&gt;. Bielefeld: Universität Bielefeld.&lt;/div&gt;</chicago>
<harvard1>Rodríguez, A., 2018. &lt;em&gt;The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing&lt;/em&gt;, Bielefeld: Universität Bielefeld.</harvard1>
<bio1>Rodríguez A (2018) &lt;br /&gt;&lt;em&gt;The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing&lt;/em&gt;.&lt;br /&gt;Bielefeld: Universität Bielefeld.</bio1>
<apa_indent>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Rodríguez, A. (2018).  &lt;em&gt;The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing&lt;/em&gt;. Bielefeld: Universität Bielefeld.&lt;/div&gt;</apa_indent>
<angewandte-chemie>A.  Rodríguez, &lt;em&gt;The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing&lt;/em&gt;, Universität Bielefeld, Bielefeld, &lt;strong&gt;2018&lt;/strong&gt;.</angewandte-chemie>
<wels>Rodríguez, A. (2018): The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing. Bielefeld: Universität Bielefeld.</wels>
<apa>Rodríguez, A. (2018).  &lt;em&gt;The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing&lt;/em&gt;. Bielefeld: Universität Bielefeld.</apa>
<ieee> A. Rodríguez, &lt;em&gt;The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing&lt;/em&gt;,  Bielefeld: Universität Bielefeld, 2018.</ieee>
<ama>Rodríguez A. &lt;em&gt;The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing&lt;/em&gt;. Bielefeld: Universität Bielefeld; 2018.</ama>
<frontiers>Rodríguez, A. (2018). The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing. Bielefeld: Universität Bielefeld.</frontiers>
<dgps>&lt;div style="text-indent:-25px; padding-left:25px;padding-bottom:0px;"&gt;Rodríguez, A. (2018). &lt;em&gt;The influence of prior visual gender and action cues versus long-term knowledge in (situated) language processing&lt;/em&gt;. Bielefeld: Universität Bielefeld.&lt;/div&gt;</dgps>
</bibliographicCitation>
</extension>
<recordInfo><recordIdentifier>2920019</recordIdentifier><recordCreationDate encoding="w3cdtf">2018-05-24T14:39:59Z</recordCreationDate><recordChangeDate encoding="w3cdtf">2018-07-24T12:58:43Z</recordChangeDate>
</recordInfo>
</mods>