<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD2305605">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo>
                        <title>Vision-based image retrieval (VBIR) : a new eye-tracking based approach to efficient and intuitive image retrieval</title>
                    </titleInfo>
                    <name type="personal">
                        <namePart type="given">Kai</namePart>
                        <namePart type="family">Essig</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Helge</namePart>
                        <namePart type="family">Ritter</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">dgs</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">doctoralThesis</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf">2007</dateIssued>
                        <dateOther encoding="w3cdtf" type="defenseDate">2007-12-17</dateOther>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <abstract lang="ger">Die vorliegende Arbeit beschreibt einen neuen Ansatz für die inhaltsbasierte Suche von Bildern in Datenbanken auf Basis von Blickbewegungsmessungen. Im Vision-Based Image Retrieval (VBIR) werden die Bilder in 16 gleich große Sektoren unterteilt, für die jeweils lokale Farb-, Form- und Texturmerkmale berechnet werden. Das Besondere am VBIR-Ansatz ist die dynamische Gewichtung lokaler Bildmerkmale (Bottom-Up Informationen) aus Aufmerksamkeitslandschaften online erfasster Blickdaten (Top-Down Informationen). Auf diese Weise passt sich das System den Präferenzen des Benutzers an. In den folgenden Suchprozessen werden dann solche Bilder ausgewählt, die dem gesuchten Bild in den bevorzugten Sektoren und Bildeigenschaften am ähnlichsten sind. Das neue System wurde in zwei Studien evaluiert, deren Ergebnisse vorgestellt werden: zum einen wird der neue Ansatz mit einem klassischen Bildsuchsystem (CBIR) verglichen. Zum anderen werden die Suchergebnisse beider Ansätze gemäß menschlichen Ähnlichkeitsbewertungen beurteilt. Die Ergebnisse belegen, dass mit dem VBIR-System eine höhere Erfolgsquote bei kürzeren mittleren Suchzeiten erreicht werden kann. Darüber hinaus werden die gefundenen Bilder als ähnlicher zum Anfragebild bewertet als beim CBIR-System.
Bei der Umsetzung der Bildsuchsysteme werden zwei zentrale Aspekte für deren Gestaltungsprozess, nämlich die Bestimmung der optimalen Gewichtung der Bildmerkmale und die Merkmalsevaluierung, genauer untersucht. Dabei wird die optimale Gewichtung der eingesetzten Merkmalstypen mittels Shannon-Entropie aus Distanzhistogrammen berechnet. Im Gegensatz zu den üblichen Ansätzen, die iterativ die Einzelgewichtungen manuell anpassen, erfordert dieses Verfahren lediglich einen Rechendurchgang. Die Evaluation der Bildmerkmale erfolgt über ein Lernverfahren, eine Selbstorganisierende Merkmalskarte (SOM), welche Bilder gemäß ihrer Merkmalsähnlichkeit auf einem 2D Gitter anordnet.
Die Arbeit schließt mit der Beschreibung von Computermodellen, mit denen die Suchprozesse für beide Bildsuchverfahren (VBIR und CBIR) in wesentlichen Zügen nachgebildet werden. Mittels eines weiteren, separaten Modells wird evaluiert, wie die verschiedenen Bildeigenschaften die Aufmerksamkeit der Probanden steuern.</abstract>
                    <abstract lang="eng">This thesis presents a novel eye-movement based approach to image retrieval. Following a so-called Vision-Based Image Retrieval (VBIR) approach, images are divided into 16 equally sized tiles. Local colour, shape and texture features are calculated for each tile. A special feature of VBIR is the dynamical adjustment of the weights of the local image features (bottom-up information) on the basis of fixation maps. These maps are calculated online from participants&apos; eye movements (top-down information). Thus, in the course of the retrieval process, the system adapts closer to users&apos; preferences and finds images that are most similar to the query image in the preferred image tiles and features. In order to evaluate the performance of the VBIR system, two experiments are conducted: for one, the new approach is compared to a classical Content-Based Image Retrieval System (CBIRS) with regard to performance and reaction times. For another, the retrieval results of both approaches are evaluated with respect to participants&apos; overall impression of similarity. The results reveal not only better retrieval performances and lower average reaction times in case of the VBIR system, but also higher ratings for the similarity between the systems&apos; retrieval results and the corresponding query images.
Two central aspects in the design process of retrieval systems are analysed: the estimation of the optimal feature weights and the evaluation of the chosen image features. The optimal feature weight combination is calculated from feature distance histograms using Shannon&apos;s entropy measure. The advantage of this method is that it requires only a single computation loop to find the optimal feature weights instead of an iterative loop of user inputs. The feature evaluation method applies a learning algorithm, the self-organizing map (SOM), which arranges images on a 2D grid according to the similarities in their feature vectors.
This thesis concludes with a description of computer models simulating retrieval processes of both approaches (VBIR and CBIRS). A second, separate model evaluates the influence of different image features on participants&apos; attention distribution.</abstract>
                    <subject>
                        <topic>Bilddatenbanksystem</topic>
                        <topic>Information Retrieval</topic>
                        <topic>Bildverstehen</topic>
                        <topic>Merkmalsextraktion</topic>
                        <topic>Inhaltsbasierte Bildsuche</topic>
                        <topic>Eyetracking</topic>
                        <topic>Visuelle Aufmerksamkeit</topic>
                        <topic>Vision-based image retrieval (VBIR)</topic>
                        <topic>Content-based image retrieval (CBIR)</topic>
                        <topic>Eye tracking</topic>
                        <topic>Visual attention</topic>
                    </subject>
                    <classification authority="ddc">004</classification>
                    <identifier type="urn">urn:nbn:de:hbz:361-12373</identifier>
                    <identifier type="sys">HT015462976</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://rightsstatements.org/vocab/InC/1.0/">Urheberrechtsschutz</accessCondition>
                    <recordInfo>
                        <recordIdentifier>bielefeld_pub_2305605</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>oaDoctoralThesis</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_bielefeld_pub_2305605">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/2305605/2305608/diss_Kai_Essig.pdf" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="bielefeld_pub_2305605" DMDID="DMD2305605">
            <mets:fptr FILEID="FILE0_bielefeld_pub_2305605"/>
        </mets:div>
    </mets:structMap>
</mets:mets>
