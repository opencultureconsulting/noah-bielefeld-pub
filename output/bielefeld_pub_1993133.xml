<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD1993133">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo>
                        <title>Towards meaningful robot gesture</title>
                    </titleInfo>
                    <name type="personal">
                        <namePart type="given">Maha</namePart>
                        <namePart type="family">Salem</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Stefan</namePart>
                        <namePart type="family">Kopp</namePart>
                        <nameIdentifier type="orcid" typeURI="http://orcid.org">0000-0002-4047-9277</nameIdentifier>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Ipke</namePart>
                        <namePart type="family">Wachsmuth</namePart>
                        <nameIdentifier type="orcid" typeURI="http://orcid.org">0000-0002-4786-5189</nameIdentifier>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Frank</namePart>
                        <namePart type="family">Joublin</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Helge</namePart>
                        <namePart type="family">Ritter</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Gerhard</namePart>
                        <namePart type="family">Sagerer</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Rüdiger</namePart>
                        <namePart type="family">Dillmann</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Martin</namePart>
                        <namePart type="family">Buss</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">bookPart</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf">2009</dateIssued>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <abstract lang="eng">Humanoid robot companions that are intended to engage in natural and fluent human-robot interaction are supposed to combine speech with non-verbal modalities for  comprehensible and believable behavior. We present an approach to enable the humanoid robot ASIMO to flexibly produce and synchronize speech and co-verbal gestures at run-time, while not being limited to a predefined repertoire of motor action. Since this research challenge has already been tackled in various ways within the domain of virtual conversational agents, we build upon the experience gained from the development of a speech and gesture production model used for our virtual human Max. Being one of the most sophisticated multi-modal schedulers, the Articulated Communicator Engine (ACE) has replaced the use of lexicons of canned behaviors with an on-the-spot production of flexibly planned behavior representations. As an underlying action generation architecture, we explain how ACE draws upon a tight, bi-directional coupling of ASIMO’s perceptuo-motor system with multi-modal scheduling via both efferent control signals and afferent feedback.</abstract>
                    <subject>
                    </subject>
                    <classification authority="ddc">006</classification>
                    <relatedItem type="host">
                        <titleInfo>
                            <title>Human Centered Robot Systems: Cognition, Interaction, Technology</title>
                        </titleInfo>
                        <part>
                            <detail type="volume">
                                <number>6</number>
                            </detail>
                            <extent unit="page">
                                <start>173</start>
                                <end>182</end>
                            </extent>
                        </part>
                    </relatedItem>
                    <identifier type="isbn">978-3-642-10402-2</identifier>
                    <identifier type="urn">urn:nbn:de:0070-pub-19931338</identifier>
                    <identifier type="doi">10.1007/978-3-642-10403-9_18</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://rightsstatements.org/vocab/InC/1.0/">Urheberrechtsschutz</accessCondition>
                    <recordInfo>
                        <recordIdentifier>bielefeld_pub_1993133</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>oaBookPart</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_bielefeld_pub_1993133">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/1993133/2633164/HCRS2009_SalemKoppWachsmuthJoublin_TowardsMeaningfulRobotGesture.pdf" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="bielefeld_pub_1993133" DMDID="DMD1993133">
            <mets:fptr FILEID="FILE0_bielefeld_pub_1993133"/>
        </mets:div>
    </mets:structMap>
</mets:mets>
