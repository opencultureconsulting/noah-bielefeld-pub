<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD2915520">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo>
                        <title>Human-Like room segmentation for domestic cleaning robots</title>
                    </titleInfo>
                    <name type="personal">
                        <namePart type="given">David Roman</namePart>
                        <namePart type="family">Fleer</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">article</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf">2017</dateIssued>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <abstract lang="eng">Autonomous mobile robots have recently become a popular solution for automating cleaning tasks. In one application, the robot cleans a floor space by traversing and covering it completely. While fulfilling its task, such a robot may create a map of its surroundings. For domestic indoor environments, these maps often consist of rooms connected by passageways. Segmenting the map into these rooms has several uses, such as hierarchical planning of cleaning runs by the robot, or the definition of cleaning plans by the user. Especially in the latter application, the robot-generated room segmentation should match the human understanding of rooms. Here, we present a novel method that solves this problem for the graph of a topo-metric map: first, a classifier identifies those graph edges that cross a border between rooms. This classifier utilizes data from multiple robot sensors, such as obstacle measurements and camera images. Next, we attempt to segment the map at these roomâ€“border edges using graph clustering. By training the classifier on user-annotated data, this produces a human-like room segmentation. We optimize and test our method on numerous realistic maps generated by our cleaning-robot prototype and its simulated version. Overall, we find that our method produces more human-like room segmentations compared to mere graph clustering. However, unusual room borders that differ from the training data remain a challeng</abstract>
                    <subject>
                        <topic>room segmentation</topic>
                        <topic>domestic cleaning robots</topic>
                        <topic>machine learning</topic>
                        <topic>computer vision</topic>
                    </subject>
                    <classification authority="ddc">000</classification>
                    <relatedItem type="host">
                        <titleInfo>
                            <title>Robotics</title>
                        </titleInfo>
                        <part>
                            <detail type="volume">
                                <number>6</number>
                            </detail>
                            <detail type="issue">
                                <number>4</number>
                            </detail>
                        </part>
                    </relatedItem>
                    <identifier type="eIssn">2218-6581</identifier>
                    <identifier type="ISI">000419218500014</identifier>
                    <identifier type="urn">urn:nbn:de:0070-pub-29155209</identifier>
                    <identifier type="doi">10.3390/robotics6040035</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</accessCondition>
                    <recordInfo>
                        <recordIdentifier>bielefeld_pub_2915520</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>oaArticle</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_bielefeld_pub_2915520">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/2915520/2915521/robotics-06-00035-v2.fleer.pdf" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="bielefeld_pub_2915520" DMDID="DMD2915520">
            <mets:fptr FILEID="FILE0_bielefeld_pub_2915520"/>
        </mets:div>
    </mets:structMap>
</mets:mets>
