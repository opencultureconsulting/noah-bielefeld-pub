<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD2911886">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo>
                        <title>Hand-Object Interaction Detection with Fully Convolutional Networks</title>
                    </titleInfo>
                    <name type="personal">
                        <namePart type="given">Matthias</namePart>
                        <namePart type="family">Schröder</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Helge</namePart>
                        <namePart type="family">Ritter</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">conferenceObject</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf">2017</dateIssued>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <abstract lang="eng">Detecting hand-object interactions is a challenging
problem with many applications in the human-computer interaction
domain. We present a real-time method that automatically
detects hand-object interactions in RGBD sensor
data and tracks the object’s rigid pose over time. The
detection is performed using a fully convolutional neural
network, which is purposefully trained to discern the relationship
between hands and objects and which predicts
pixel-wise class probabilities. This output is used in a probabilistic
pixel labeling strategy that explicitly accounts for
the uncertainty of the prediction. Based on the labeling of
object pixels, the object is tracked over time using modelbased
registration. We evaluate the accuracy and generalizability
of our approach and make our annotated RGBD
dataset as well as our trained models publicly available.</abstract>
                    <subject>
                    </subject>
                    <classification authority="ddc">000</classification>
                    <identifier type="urn">urn:nbn:de:0070-pub-29118861</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://rightsstatements.org/vocab/InC/1.0/">Urheberrechtsschutz</accessCondition>
                    <recordInfo>
                        <recordIdentifier>bielefeld_pub_2911886</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>conference_object</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_bielefeld_pub_2911886">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/2911886/2911887/paper.pdf" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="bielefeld_pub_2911886" DMDID="DMD2911886">
            <mets:fptr FILEID="FILE0_bielefeld_pub_2911886"/>
        </mets:div>
    </mets:structMap>
</mets:mets>
