<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD2532745">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo>
                        <title>Head gesture sonification for supporting social interaction</title>
                    </titleInfo>
                    <name type="personal">
                        <namePart type="given">Thomas</namePart>
                        <namePart type="family">Hermann</namePart>
                        <nameIdentifier type="orcid" typeURI="http://orcid.org">0000-0001-7975-4363</nameIdentifier>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Alexander</namePart>
                        <namePart type="family">Neumann</namePart>
                        <nameIdentifier type="orcid" typeURI="http://orcid.org">0000-0002-2190-5576</nameIdentifier>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Sebastian</namePart>
                        <namePart type="family">Zehe</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Andreas</namePart>
                        <namePart type="family">Floros</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Iani</namePart>
                        <namePart type="family">Zannos</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">conferenceObject</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf">2012</dateIssued>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <abstract lang="eng">In this paper we introduce two new methods for real-time sonification of head movements and head gestures. Head gestures such as nodding or shaking the head are important non-verbal back-channelling signals which facilitate coordination and alignment of communicating interaction partners. Visually impaired persons cannot interpret such non-verbal signals, same as people in mediated communication (e.g. on the phone), or cooperating users whose visual attention is focused elsewhere. We introduce our approach to tackle these issues, our sensing setup and two different sonification methods. A first preliminary study on the recognition of signals shows that subjects understand the gesture type even without prior explanation and can estimate gesture intensity and frequency with no or little training.</abstract>
                    <subject>
                        <topic>social interaction</topic>
                        <topic>assistive technology</topic>
                        <topic>head gestures</topic>
                        <topic>mediated communication</topic>
                        <topic>auditory display</topic>
                        <topic>sonification</topic>
                    </subject>
                    <classification authority="ddc">004</classification>
                    <identifier type="isbn">978-1-4503-1569-2</identifier>
                    <identifier type="urn">urn:nbn:de:0070-pub-25327454</identifier>
                    <identifier type="doi">10.1145/2371456.2371469</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://rightsstatements.org/vocab/InC/1.0/">Urheberrechtsschutz</accessCondition>
                    <recordInfo>
                        <recordIdentifier>bielefeld_pub_2532745</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>conference_object</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_bielefeld_pub_2532745">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/2532745/2638091/2012_Hermann__Neumann__Zehe_Head_gesture_sonification_for_supporting_social_interaction.pdf" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="bielefeld_pub_2532745" DMDID="DMD2532745">
            <mets:fptr FILEID="FILE0_bielefeld_pub_2532745"/>
        </mets:div>
    </mets:structMap>
</mets:mets>
