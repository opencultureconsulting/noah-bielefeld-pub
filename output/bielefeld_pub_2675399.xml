<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD2675399">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo>
                        <title>Listening-Mode-Centered Sonification Design for Data Exploration</title>
                    </titleInfo>
                    <name type="personal">
                        <namePart type="given">Florian</namePart>
                        <namePart type="family">Grond</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Thomas</namePart>
                        <namePart type="family">Hermann</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">dgs</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">doctoralThesis</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf">2013</dateIssued>
                        <dateOther encoding="w3cdtf" type="defenseDate">2013-12-05</dateOther>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <abstract lang="eng">From the Introduction to this thesis:
Through the ever growing amount of data and the desire to make them accessible to the user through the sense of listening, sonification, the representation of data by using sound has been subject of active research in the computer sciences and the field of HCI for the last 20 years. During this time, the field of sonification has diversified into different application areas: today, sound in auditory display informs the user about states and actions on the desktop and in mobile devices; sonification has been applied in monitoring applications, where sound can range from being informative to alarming; sonification has been used to give sensory feedback in order to close the action and perception loop; last but not least, sonifications have also been developed for exploratory data analysis, where sound is used to represent data with unknown structures for hypothesis building.
Coming from the computer sciences and HCI, the conceptualization of sonification has been mostly driven by application areas. On the other hand, the sonic arts who have always contributed to the community of auditory display have a genuine focus on sound. Despite this close interdisciplinary relation of communities of sound practitioners, a rich and sound- (or listening)-centered concept about sonification is still missing as a point of departure for a more application and task overarching approach towards design guidelines. Complementary to the useful organization along fields of applications, a conceptual framework that is proper to sound needs to abstract from applications and also to some degree from tasks, as both are not directly related to sound. I hence propose in this thesis to conceptualize sonifications along two poles where sound serves either a normative or a descriptive purpose.
In the beginning of auditory display research, a continuum between a symbolic and an analogic pole has been proposed by Kramer (1994a, page 21). In this continuum, symbolic stands for sounds that coincide with existing schemas and are more denotative, analogic stands for sounds that are informative through their connotative aspects. (compare Worrall (2009, page 315)). The notions of symbolic and analogic illustrate the struggle to find apt descriptions of how the intention of the listener subjects audible phenomena to a process of meaning making and interpretation. Complementing the analogic-symbolic continuum with descriptive and normative purposes of displays is proposed in the light of the recently increased research interest in listening modes and intentions.
Similar to the terms symbolic and analogic, listening modes have been discussed in auditory display since the beginning usually in dichotomic terms which were either identified with the words listening and hearing or understood as musical listening and everyday listening as proposed by Gaver (1993a). More than 25 years earlier, four direct listening modes have been introduced by Schaeffer (1966) together with a 5th synthetic mode of reduced listening which leads to the well-known sound object. Interestingly, Schaeffer’s listening modes remained largely unnoticed by the auditory display community. Particularly the notion of reduced listening goes beyond the connotative and denotative poles of the continuum proposed by Kramer and justifies the new terms descriptive and normative. Recently, a new taxonomy of listening modes has been proposed by Tuuri and Eerola (2012) that is motivated through an embodied cognition approach. The main contribution of their taxonomy is that it convincingly diversifies the connotative and denotative aspects of listening modes. In the recently published sonification handbook, multimodal and interactive aspects in combination with sonification have been discussed as promising options to expand and advance the field by Hunt and Hermann (2011), who point out that there is a big need for a better theoretical foundation in order to systematically integrate these aspects. The main contribution of this thesis is to address this need by providing alternative and complementary design guidelines with respect to existing approaches, all of which have been conceived before the recently increased research interest in listening modes. None of the existing contributions to design frameworks integrates multimodality, and listening modes with a focus on exploratory data analysis, where sonification is conceived to support the understanding of complex data potentially helping to identify new structures therein. In order to structure this field the following questions are addressed in this thesis:
• How do natural listening modes and reduced listening relate to the proposed normative and descriptive display purposes?
• What is the relationship of multimodality and interaction with listening modes and display purposes?
• How can the potential of embodied cognition based listening modes be put to use for exploratory data sonification?
• How can listening modes and display purposes be connected to questions of aesthetics in the display?
• How do data complexity and Parameter-mapping sonification relate to exploratory data analysis and listening modes?</abstract>
                    <subject>
                        <topic>auditory display</topic>
                        <topic>sonic interaction design</topic>
                        <topic>human factors</topic>
                        <topic>sonification</topic>
                        <topic>human computer interaction</topic>
                    </subject>
                    <classification authority="ddc">000</classification>
                    <identifier type="urn">urn:nbn:de:hbz:361-26753990</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://rightsstatements.org/vocab/InC/1.0/">Urheberrechtsschutz</accessCondition>
                    <recordInfo>
                        <recordIdentifier>bielefeld_pub_2675399</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>oaDoctoralThesis</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_bielefeld_pub_2675399">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/2675399/2675400/Listening-Mode-Centered_Sonification_Design_for_Data_Exploration__FlorianGrond.pdf" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
        <mets:fileGrp USE="generic file">
            <mets:file MIMETYPE="application/x-gzip" ID="FILE1_bielefeld_pub_2675399">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/2675399/2678755/SoundExamples.tar.gz" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="bielefeld_pub_2675399" DMDID="DMD2675399">
            <mets:fptr FILEID="FILE0_bielefeld_pub_2675399"/>
            <mets:div TYPE="part" ID="PART1_2675399" LABEL="SoundExamples.tar.gz">
                <mets:fptr FILEID="FILE1_bielefeld_pub_2675399"/>
            </mets:div>
        </mets:div>
    </mets:structMap>
</mets:mets>
