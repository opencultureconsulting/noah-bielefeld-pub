<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD2906512">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo>
                        <title>Peripheral Processing Facilitates Optic Flow-Based Depth Perception</title>
                    </titleInfo>
                    <name type="personal">
                        <namePart type="given">Jinglin</namePart>
                        <namePart type="family">Li</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Jens Peter</namePart>
                        <namePart type="family">Lindemann</namePart>
                        <nameIdentifier type="orcid" typeURI="http://orcid.org">0000-0002-5441-7931</nameIdentifier>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Martin</namePart>
                        <namePart type="family">Egelhaaf</namePart>
                        <nameIdentifier type="orcid" typeURI="http://orcid.org">0000-0002-9336-4270</nameIdentifier>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">article</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf">2016</dateIssued>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <abstract lang="eng">Flying insects, such as flies or bees, rely on consistent information regarding the
depth structure of the environment when performing their flight maneuvers in cluttered natural 
environments. These behaviors include avoiding collisions, approaching targets or spatial 
navigation. Insects are thought to obtain depth information visually from the retinal image 
displacements (“optic flow”) during translational ego-motion. Optic flow in the insect visual 
system is processed by a mechanism that can be modeled by correlation-type elementary motion 
detectors (EMDs). However, it is still an open question how spatial information can be extracted 
reliably from the responses of the highly contrast- and pattern-dependent EMD responses, especially 
if the vast range of light intensities encountered in natural environments is taken into account. 
This question will be addressed here by systematically modeling the peripheral visual system of 
flies, including various adaptive mechanisms. Different model variants of the peripheral visual 
system were stimulated with image sequences that mimic the panoramic visual input during 
translational ego-motion in various natural environments, and the resulting peripheral signals were 
fed into an array of EMDs. We characterized the influence of each peripheral computational unit on 
the representation of spatial information in the EMD responses. Our model simulations reveal that 
information about the overall light level needs to be eliminated from the EMD input as is 
accomplished under light-adapted conditions in the insect peripheral visual system. The response 
characteristics of large monopolar cells (LMCs) resemble that of a band-pass filter, which reduces 
the contrast dependency of EMDs strongly, effectively enhancing the representation of the nearness 
of objects and, especially, of their contours. We furthermore show that local brightness adaptation 
of photoreceptors allows for spatial vision under a wide range of dynamic light
conditions.</abstract>
                    <subject>
                        <topic>spatial vision</topic>
                        <topic>optic flow</topic>
                        <topic>brightness adaptation</topic>
                        <topic>photoreceptors</topic>
                        <topic>LMCs</topic>
                        <topic>computational modeling</topic>
                        <topic>fly</topic>
                        <topic>natural environments</topic>
                    </subject>
                    <classification authority="ddc">570</classification>
                    <relatedItem type="host">
                        <titleInfo>
                            <title>Frontiers in Computational Neuroscience</title>
                        </titleInfo>
                        <part>
                            <detail type="volume">
                                <number>10</number>
                            </detail>
                            <detail type="issue">
                                <number>10</number>
                            </detail>
                        </part>
                    </relatedItem>
                    <identifier type="issn">1662-5188</identifier>
                    <identifier type="MEDLINE">27818631</identifier>
                    <identifier type="ISI">000385966400001</identifier>
                    <identifier type="urn">urn:nbn:de:0070-pub-29065125</identifier>
                    <identifier type="doi">10.3389/fncom.2016.00111</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://rightsstatements.org/vocab/InC/1.0/">Urheberrechtsschutz</accessCondition>
                    <recordInfo>
                        <recordIdentifier>bielefeld_pub_2906512</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>oaArticle</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_bielefeld_pub_2906512">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/2906512/2906514/Li_et_al_FrontCompNeurosci_2016.pdf" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="bielefeld_pub_2906512" DMDID="DMD2906512">
            <mets:fptr FILEID="FILE0_bielefeld_pub_2906512"/>
        </mets:div>
    </mets:structMap>
</mets:mets>
