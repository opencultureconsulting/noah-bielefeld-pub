<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD2017244">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo>
                        <title>Sonification and Sonic Interaction Design for the Broadband Society</title>
                    </titleInfo>
                    <name type="personal">
                        <namePart type="given">Thomas</namePart>
                        <namePart type="family">Hermann</namePart>
                        <nameIdentifier type="orcid" typeURI="http://orcid.org">0000-0001-7975-4363</nameIdentifier>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">B.</namePart>
                        <namePart type="family">Sapio</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">L.</namePart>
                        <namePart type="family">Haddon</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">E.</namePart>
                        <namePart type="family">Mante-Meijer</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">L.</namePart>
                        <namePart type="family">Fortunati</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">T.</namePart>
                        <namePart type="family">Turk</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">E.</namePart>
                        <namePart type="family">Loos</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">conferenceObject</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf">2009</dateIssued>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <abstract lang="eng">&lt;img src=&quot;https://pub.uni-bielefeld.de/download/2017244/2911173&quot; width=&quot;60%&quot; height=&quot;60%&quot; style=&quot;float:right;&quot;/&gt; Imagine a huge dataset of a public census - or medical data - or the worldwide Internet traffic. What do you hear? Obviously, we are not very familiar with the use of our listening capabilities when investigating large amounts of information! The typical data analyst is indeed confronted with large visual displays showing visualizations in front of a (concerning information value) rather silent computer. This is interesting since sound plays a highly important role in most real-world contexts, e.g. to monitor complex processes, to analyze complex systems, to selectively direct our attention, to allow us to gain insight into systems beyond the surface. Sonification, the auditory display of information makes arbitrary data accessible by our listening skills and addresses complementary modes of understanding which put dynamic instead of static features into the fore, which are well connected to interaction. Sonification can play an important role for the broadband society, e.g. to increase awareness of network behavior, our virtual neighborhood, to feel connected without being bound to a visual display. The paper will introduce, demonstrate and discuss the utility of sonification in sonic interaction design from monitoring and analysis tasks, interactive biofeedback to interfaces for visually impaired, introduce the concept of Sonic Overloading, and furthermore relate sonification to expected trends in the broadband society.</abstract>
                    <subject>
                    </subject>
                    <classification authority="ddc">000</classification>
                    <relatedItem type="host">
                        <titleInfo>
                            <title>The good, the bad and the challenging: The user and the future of information and communication technologies: Conference proceedings</title>
                        </titleInfo>
                        <part>
                            <detail type="volume">
                                <number>2</number>
                            </detail>
                            <extent unit="page">
                                <start>887</start>
                                <end>892</end>
                            </extent>
                        </part>
                    </relatedItem>
                    <identifier type="isbn">ISBN 978-961-6277-17-4</identifier>
                    <identifier type="urn">urn:nbn:de:0070-pub-20172448</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://rightsstatements.org/vocab/InC/1.0/">Urheberrechtsschutz</accessCondition>
                    <recordInfo>
                        <recordIdentifier>bielefeld_pub_2017244</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>conference_object</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_bielefeld_pub_2017244">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/2017244/2277489/Hermann2009-SAS.pdf" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
        <mets:fileGrp USE="generic file">
            <mets:file MIMETYPE="image/jpeg" ID="FILE1_bielefeld_pub_2017244">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/2017244/2911173/figure.jpg" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="bielefeld_pub_2017244" DMDID="DMD2017244">
            <mets:fptr FILEID="FILE0_bielefeld_pub_2017244"/>
            <mets:div TYPE="part" ID="PART1_2017244" LABEL="figure.jpg">
                <mets:fptr FILEID="FILE1_bielefeld_pub_2017244"/>
            </mets:div>
        </mets:div>
    </mets:structMap>
</mets:mets>
