<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD2097157">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo>
                        <title>Regulating Dialogue With Gestures---Towards an Empirically Grounded Simulation with Conversational Agents</title>
                    </titleInfo>
                    <name type="personal">
                        <namePart type="given">Kirsten</namePart>
                        <namePart type="family">Bergmann</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Hannes</namePart>
                        <namePart type="family">Rieser</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Stefan</namePart>
                        <namePart type="family">Kopp</namePart>
                        <nameIdentifier type="orcid" typeURI="http://orcid.org">0000-0002-4047-9277</nameIdentifier>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">J.Y.</namePart>
                        <namePart type="family">Chai</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">J.D.</namePart>
                        <namePart type="family">Moore</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">R.J.</namePart>
                        <namePart type="family">Passonneau</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">D.R.</namePart>
                        <namePart type="family">Traum</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">conferenceObject</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf">2011</dateIssued>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <abstract lang="eng">Although not very well investigated, a crucial aspect of gesture use in dialogues is to regulate the organisation of the interaction. People use gestures decisively, for example to indicate that they want someone to take the turn, to &apos;brush away&apos; what someone else said, or to acknowledge others&apos; contributions. We present first insights from a corpus-based investigation of how gestures are used to regulate dialogue, and we provide first results from an account to capture these phenomena in agent-based communication simulations. By advancing a model for autonomous gesture generation to also cover gesture interpretation, this account enables a full gesture turn exchange cycle of generation, understanding and acceptance/generation in virtual conversational agents.</abstract>
                    <subject>
                    </subject>
                    <classification authority="ddc">400</classification>
                    <identifier type="urn">urn:nbn:de:0070-pub-20971570</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://rightsstatements.org/vocab/InC/1.0/">Urheberrechtsschutz</accessCondition>
                    <recordInfo>
                        <recordIdentifier>bielefeld_pub_2097157</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>conference_object</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_bielefeld_pub_2097157">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/2097157/2410351/BergmannRieserKopp_SigDial2011_final.pdf" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="bielefeld_pub_2097157" DMDID="DMD2097157">
            <mets:fptr FILEID="FILE0_bielefeld_pub_2097157"/>
        </mets:div>
    </mets:structMap>
</mets:mets>
