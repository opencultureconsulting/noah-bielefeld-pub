<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD1857802">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo>
                        <title>Engagement in Collaborative Construction Tasks with Max</title>
                    </titleInfo>
                    <name type="personal">
                        <namePart type="given">Nadine</namePart>
                        <namePart type="family">Leßmann</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Stefan</namePart>
                        <namePart type="family">Kopp</namePart>
                        <nameIdentifier type="orcid" typeURI="http://orcid.org">0000-0002-4047-9277</nameIdentifier>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">conferenceObject</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf">2005</dateIssued>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <abstract lang="eng">In Virtual Reality environments, real humans can meet
virtual humans to collaborate on tasks. The agent Max is
such a virtual human. In construction tasks, he is standing
face-to-face to a human partner as a co-situated companion.
To maintain a social conversation, Max has to perceive
the user’s engagement and to solicit the user’s engagement,
he needs to demonstrate engagement himself. This paper
presents ongoing work on the development of a model that
describes interacting levels of engagement. We present how
the agent’s perceptive, cognitive, and expressive capabilities interact on these levels ranging from observing the human partner, to taking her goals, mental state or emotions into account when making decisions on how to interact and intervene.</abstract>
                    <subject>
                    </subject>
                    <classification authority="ddc">006</classification>
                    <identifier type="urn">urn:nbn:de:0070-pub-18578022</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://rightsstatements.org/vocab/InC/1.0/">Urheberrechtsschutz</accessCondition>
                    <recordInfo>
                        <recordIdentifier>bielefeld_pub_1857802</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>conference_object</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_bielefeld_pub_1857802">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/1857802/2634809/EngagementWithMax.pdf" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="bielefeld_pub_1857802" DMDID="DMD1857802">
            <mets:fptr FILEID="FILE0_bielefeld_pub_1857802"/>
        </mets:div>
    </mets:structMap>
</mets:mets>
