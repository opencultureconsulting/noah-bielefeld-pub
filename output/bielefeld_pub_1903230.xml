<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD1903230">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo>
                        <title>Requirements and Building Blocks for Sociable Embodied Agents</title>
                    </titleInfo>
                    <name type="personal">
                        <namePart type="given">Stefan</namePart>
                        <namePart type="family">Kopp</namePart>
                        <nameIdentifier type="orcid" typeURI="http://orcid.org">0000-0002-4047-9277</nameIdentifier>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Kirsten</namePart>
                        <namePart type="family">Bergmann</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Hendrik</namePart>
                        <namePart type="family">Buschmeier</namePart>
                        <nameIdentifier type="orcid" typeURI="http://orcid.org">0000-0002-9613-5713</nameIdentifier>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Amir</namePart>
                        <namePart type="family">Sadeghipour</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">aut</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">B.</namePart>
                        <namePart type="family">Mertsching</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">M.</namePart>
                        <namePart type="family">Hund</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <namePart type="given">Z.</namePart>
                        <namePart type="family">Aziz</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">edt</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">conferenceObject</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf">2009</dateIssued>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <abstract lang="eng">To be sociable, embodied interactive agents like virtual characters or humanoid robots need to be able to engage in mutual coordination of behaviors, beliefs, and relationships with their human interlocutors. We argue that this requires them to be capable of flexible multimodal expressiveness, incremental perception of otherâ€™s behaviors, and the integration and interaction of these models in unified sensorimotor structures. We present work on probabilistic models for these three requirements with a focus on gestural behavior.</abstract>
                    <subject>
                    </subject>
                    <classification authority="ddc">006</classification>
                    <identifier type="urn">urn:nbn:de:0070-pub-19032307</identifier>
                    <identifier type="doi">10.1007/978-3-642-04617-9_64</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://rightsstatements.org/vocab/InC/1.0/">Urheberrechtsschutz</accessCondition>
                    <recordInfo>
                        <recordIdentifier>bielefeld_pub_1903230</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>conference_object</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_bielefeld_pub_1903230">
                <mets:FLocat xlink:href="https://pub.uni-bielefeld.de/download/1903230/2683143/Kopp-etal-2009-KI-preprint.pdf" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="bielefeld_pub_1903230" DMDID="DMD1903230">
            <mets:fptr FILEID="FILE0_bielefeld_pub_1903230"/>
        </mets:div>
    </mets:structMap>
</mets:mets>
